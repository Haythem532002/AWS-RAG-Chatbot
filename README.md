# ğŸ¤– AWS RAG Chatbot

**Intelligent Documentation Assistant**

A modern RAG (Retrieval-Augmented Generation) chatbot system that provides intelligent answers about AWS services using advanced AI technology, featuring document processing, semantic search, and a beautiful web interface.

[![Python](https://img.shields.io/badge/Python-3.8+-3776ab?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.3.0-000000?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15.5.4-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3.0-1c3c3c?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Latest-ff6b6b?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.ai/)

## ğŸŒŸ Features

- ğŸ§  **Intelligent Q&A** - Advanced RAG system for AWS documentation queries
- ï¿½ **Document Processing** - Automated PDF parsing and text chunking
- ï¿½ **Semantic Search** - Vector-based similarity search with ChromaDB
- ğŸ’¬ **Modern Chat Interface** - Elegant, responsive web UI with real-time chat
- ğŸ“Š **Source Attribution** - Detailed source references with confidence scores
- âš¡ **Local AI Models** - Powered by Ollama for privacy and performance
- ğŸ¨ **Beautiful UI** - Glassmorphism design with smooth animations
- ï¿½ **Responsive Design** - Works perfectly on desktop, tablet, and mobile

## ğŸ› ï¸ Tech Stack

**Backend:** Python 3.8+, Flask, LangChain, ChromaDB  
**Frontend:** Next.js 15, TypeScript, Tailwind CSS, React  
**AI/ML:** Ollama, nomic-embed-text, Mistral LLM  
**Vector Database:** ChromaDB with persistence  
**Document Processing:** PyPDF, LangChain Text Splitters  
**API:** RESTful API with CORS support

## ğŸ–¼ï¸ System Screenshots

<div align="center">
  <img src="./rag/Capture d'Ã©cran 2025-10-02 115121.png" width="400" alt="RAG Chatbot Interface"/>
  <img src="./rag/Capture d'Ã©cran 2025-10-02 140024.png" width="400" alt="Chat Conversation Example"/>
</div>

## ğŸ—ï¸ RAG Architecture

The system follows a modern RAG (Retrieval-Augmented Generation) architecture:

### Core Components

- **ï¿½ Document Loader** - PDF processing and text extraction from AWS documentation
- **âœ‚ï¸ Text Splitter** - Intelligent chunking with overlap for context preservation
- **ï¿½ Embedding Function** - Vector embeddings using nomic-embed-text model
- **ğŸ—„ï¸ Vector Database** - ChromaDB for efficient similarity search
- **ğŸ¤– LLM Integration** - Mistral model via Ollama for response generation
- **ğŸŒ Web Interface** - Next.js frontend with real-time chat capabilities

### Data Flow

1. **ï¿½ Document Ingestion** - PDF documents are loaded and processed
2. **âš¡ Text Processing** - Documents are split into overlapping chunks
3. **ğŸ”¢ Vectorization** - Text chunks are converted to vector embeddings
4. **ï¿½ Storage** - Vectors and metadata stored in ChromaDB
5. **ï¿½ Query Processing** - User queries are embedded and matched against stored vectors
6. **ğŸ¤– Response Generation** - Retrieved context is used to generate accurate responses
7. **ï¿½ UI Display** - Results shown with sources and confidence scores

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 18+
- Ollama installed locally
- Git

### Environment Setup

1. **Clone the repository**

```bash
git clone https://github.com/Haythem532002/RAG-Chatbot.git
cd RAG-Chatbot
```

2. **Set up Python virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install Python dependencies**

```bash
pip install -r requirements.txt
```

4. **Install and setup Ollama models**

```bash
# Install Ollama (if not already installed)
curl -fsSL https://ollama.ai/install.sh | sh

# Pull required models
ollama pull nomic-embed-text
ollama pull mistral
```

### Running the Application

#### Backend Setup

1. **Process your documents** (one-time setup)

```bash
python load_data.py --reset
```

2. **Start the Flask backend**

```bash
python flask_backend.py
```

The backend will be available at `http://localhost:5000`

#### Frontend Setup

1. **Navigate to frontend directory**

```bash
cd rag-chatbot-frontend
```

2. **Install frontend dependencies**

```bash
npm install
```

3. **Start the Next.js development server**

```bash
npm run dev
```

The frontend will be available at `http://localhost:3000`

### Quick Test

Test the system via command line:

```bash
python query_data.py "What is Amazon EC2?"
```

Or test the API directly:

```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is AWS Lambda?"}'
```

### Service Endpoints

- **ğŸŒ Web Interface**: http://localhost:3000
- **ï¿½ Flask API**: http://localhost:5000
- **ï¿½ Health Check**: http://localhost:5000/
- **ï¿½ Chat API**: http://localhost:5000/api/chat
- **ğŸ¤– Ollama Server**: http://localhost:11434

## ğŸ“ Project Structure

```
RAG-Chatbot/
â”œâ”€â”€ data/                           # Source documents directory
â”‚   â”œâ”€â”€ AWS Certified Cloud Practitioner Slides v2.11.0.pdf
â”‚   â””â”€â”€ aws-overview.pdf
â”œâ”€â”€ rag/                           # Project screenshots
â”‚   â”œâ”€â”€ Capture d'Ã©cran 2025-10-02 115121.png
â”‚   â””â”€â”€ Capture d'Ã©cran 2025-10-02 140024.png
â”œâ”€â”€ chroma/                         # ChromaDB persistence directory
â”‚   â””â”€â”€ [vector database files]
â”œâ”€â”€ rag-chatbot-frontend/          # Next.js frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                   # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css        # Global styles and animations
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx         # Root layout with metadata
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx           # Main chat page
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â””â”€â”€ ChatInterface.tsx  # Main chat component
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ load_data.py                   # Document processing and vectorization
â”œâ”€â”€ query_data.py                  # Query processing and RAG pipeline
â”œâ”€â”€ embedding_function.py          # Ollama embedding integration
â”œâ”€â”€ flask_backend.py               # REST API server
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ venv/                          # Python virtual environment
â”œâ”€â”€ __pycache__/                   # Python cache files
â”œâ”€â”€ .git/                          # Git repository
â”œâ”€â”€ .gitignore                     # Git ignore file
â””â”€â”€ README.md                      # Project documentation
```

## ğŸ”§ Configuration

### Customization Options

- **ğŸ“ Document Sources**: Add your own PDFs to the `data/` directory
- **ğŸ¨ UI Themes**: Modify Tailwind classes in `globals.css`
- **ğŸ¤– Models**: Change embedding or LLM models in configuration
- **ğŸ“Š Chunk Settings**: Adjust chunk size and overlap for different document types
- **ğŸ” Search Parameters**: Modify similarity thresholds and result counts

## ğŸ“¡ API Reference

### Chat Endpoint

**POST** `/api/chat`

```json
{
  "message": "What is Amazon S3?"
}
```

**Response:**

```json
{
  "response": "Amazon S3 (Simple Storage Service) is...",
  "sources": ["data/aws-overview.pdf:15:0", "data/aws-overview.pdf:16:1"],
  "context": [
    {
      "content": "Amazon S3 provides...",
      "source": "data/aws-overview.pdf:15:0",
      "score": 0.85,
      "page": "15",
      "file": "data/aws-overview.pdf"
    }
  ],
  "num_sources": 2,
  "query": "What is Amazon S3?",
  "status": "success"
}
```

### Health Check

**GET** `/`

```json
{
  "status": "healthy",
  "message": "RAG Chatbot API is running",
  "endpoints": {
    "chat": "POST /api/chat",
    "health": "GET /"
  }
}
```

## ğŸ§ª Testing

### Run Embedding Tests

```bash
# Comprehensive embedding tests
python test_embeddings.py

# Quick functionality test
python quick_test.py
```

### Test Individual Components

```bash
# Test document loading
python load_data.py

# Test query processing
python query_data.py "test query"

# Test embedding function
python -c "from embedding_function import create_embedding_function; print('Embeddings OK')"
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Install development dependencies (`pip install -r requirements-dev.txt`)
4. Make your changes with proper tests
5. Commit your changes (`git commit -m 'Add AmazingFeature'`)
6. Push to the branch (`git push origin feature/AmazingFeature`)
7. Open a Pull Request

### Development Guidelines

- Follow PEP 8 for Python code
- Use TypeScript for frontend development
- Write tests for new features
- Update documentation for API changes
- Use conventional commits for clear history

## ï¿½ Monitoring and Performance

- **âš¡ Response Times**: Typical query response under 2-3 seconds
- **ğŸ¯ Accuracy**: High-quality responses with source attribution
- **ï¿½ Storage**: Efficient vector storage with ChromaDB
- **ğŸ” Search Quality**: Semantic similarity matching with confidence scores
- **ï¿½ UI Performance**: Optimized React components with smooth animations

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **ğŸ¦œ LangChain** for the excellent RAG framework
- **ğŸ¤– Ollama** for local AI model hosting
- **âš¡ Next.js** for the amazing React framework
- **ğŸ¨ Tailwind CSS** for beautiful styling utilities
- **ğŸ“Š ChromaDB** for efficient vector storage

---

**Built with â¤ï¸ using Modern AI & RAG Architecture**
